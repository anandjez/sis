{'wandb': {'project': 'sis', 'resume': 'allow', 'mode': 'run', 'name': '2024-04-15/12-15-35,', 'tags': [], 'id': '977854c8c2df2ad1644aed5818100d6983dfbc1c9081ff253f46bfdc0fdbf442'}, 'keops_build_path': '/Users/ajgeorge/.cache/keops/unknown/2024-04-15/12-15-35', 'merge_wandb_resume_cfg': True, 'restore_ckpt_from_wandb': True, 'target': {'_target_': 'stint_sampler.targets.targets.gmm', 'mean': 5.0, 'var': 1.0}, 'interpolant': {'_target_': 'stint_sampler.stint.linearInterpolants.linear', 'type': 'sin'}, 'model': {'_target_': 'stint_sampler.models.scoreNets.DenseNet', 'dim': 2, 'features': [20, 50, 200, 200, 50]}, 'seed': 1, 'T': 1.0, 'dim': 2, 'eps0': 1e-05, 'eps1': 1e-05, 'batch_size': 128, 'log_interval': 10, 'eval_interval': 200, 'train': {'NtTrain': 50, 'epochs': 1000, 'epoch_steps': 4, 'learning_rate': 0.01}, 'solver': {'_target_': 'stint_sampler.stint.sis.half_sis'}, 'sampler': {'Nsamples': 10000, 'NtSampler': 1000}, 'eval': {'hist_dims': [0, 1]}, 'out_dir': '/Users/ajgeorge/python/sis/logs/2024-04-15/12-15-35'}
[2024-04-15 12:15:43,024][root][INFO] - ---------------------------------------------------------------
[2024-04-15 12:15:43,027][root][INFO] - Run config:
wandb:
  project: sis
  resume: allow
  mode: run
  name: 2024-04-15/12-15-35,
  tags: []
  id: 977854c8c2df2ad1644aed5818100d6983dfbc1c9081ff253f46bfdc0fdbf442
keops_build_path: /Users/ajgeorge/.cache/keops/unknown/2024-04-15/12-15-35
merge_wandb_resume_cfg: true
restore_ckpt_from_wandb: true
target:
  _target_: stint_sampler.targets.targets.gmm
  mean: 5.0
  var: 1.0
interpolant:
  _target_: stint_sampler.stint.linearInterpolants.linear
  type: sin
model:
  _target_: stint_sampler.models.scoreNets.DenseNet
  dim: 2
  features:
  - 20
  - 50
  - 200
  - 200
  - 50
seed: 1
T: 1.0
dim: 2
eps0: 1.0e-05
eps1: 1.0e-05
batch_size: 128
log_interval: 10
eval_interval: 200
train:
  NtTrain: 50
  epochs: 1000
  epoch_steps: 4
  learning_rate: 0.01
solver:
  _target_: stint_sampler.stint.sis.half_sis
sampler:
  Nsamples: 10000
  NtSampler: 1000
eval:
  hist_dims:
  - 0
  - 1
out_dir: /Users/ajgeorge/python/sis/logs/2024-04-15/12-15-35
[2024-04-15 12:15:43,027][root][INFO] - ---------------------------------------------------------------
[2024-04-15 12:15:43,983][jax._src.xla_bridge][INFO] - Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
[2024-04-15 12:15:43,983][jax._src.xla_bridge][INFO] - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
[2024-04-15 12:15:43,985][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: dlopen(libtpu.so, 0x0001): tried: 'libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OSlibtpu.so' (no such file), '/Users/ajgeorge/anaconda3/envs/sis/lib/python3.11/site-packages/jaxlib/../../../libtpu.so' (no such file), '/Users/ajgeorge/anaconda3/envs/sis/bin/../lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache), 'libtpu.so' (no such file), '/usr/local/lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache)
[2024-04-15 12:15:44,109][root][INFO] - Checkpoint directory: /Users/ajgeorge/python/sis/logs/2024-04-15/12-15-35/ckpt
loss =  -2.438921
loss =  -4.671649
loss =  -8.595787
loss =  -7.924082
loss =  -9.243613
loss =  -9.243551
loss =  -9.224333
loss =  -8.306124
loss =  -8.043947
loss =  -9.016969
loss =  -9.351067
loss =  -8.549685
loss =  -6.426424
loss =  -7.32962
loss =  -9.415684
loss =  -8.7241955
loss =  -9.187362
loss =  -7.977991
loss =  -9.936292
loss =  -9.30846
loss =  -9.528673
loss =  -9.233732
loss =  -8.898021
loss =  -6.7541647
loss =  -7.824504
loss =  -7.9462037
loss =  -6.504591
loss =  -9.137251
loss =  -7.4331036
loss =  -9.99092
loss =  -9.441656
loss =  -7.3286448
loss =  -9.8601
loss =  -7.9487314
loss =  -9.171808
loss =  -8.1824
loss =  -9.600544
loss =  -7.642775
loss =  -7.78472
loss =  -7.5041685
loss =  -9.599405
loss =  -9.7441025
loss =  -8.17363
loss =  -9.566463
loss =  -8.81444
loss =  -10.131597
loss =  -8.859219
loss =  -8.236753
loss =  -9.185635
loss =  -8.52125
loss =  -8.461373
loss =  -7.7715216
loss =  -9.509405
loss =  -10.361273
loss =  -8.544624
loss =  -9.795034
loss =  -9.689844
loss =  -10.038719
loss =  -6.980385
loss =  -7.1202955
loss =  -4.0910797
loss =  -7.2698183
loss =  -8.743383
loss =  -6.525453
loss =  -7.841898
loss =  -7.6100245
loss =  -4.383808
loss =  -5.7047367
loss =  -7.7078753
loss =  -8.949419
loss =  -5.268319
loss =  -8.092629
loss =  -8.029289
loss =  -9.340185
loss =  -7.9835567
loss =  -8.969755
loss =  -7.744092
loss =  -7.095088
loss =  -9.012562
loss =  -8.678513
loss =  -8.587445
loss =  -8.297891
loss =  -8.597233
loss =  -7.523232
loss =  -8.580998
loss =  -7.7776794
loss =  -9.269997
loss =  -8.469582
loss =  -8.75005
loss =  -6.8431473
loss =  -9.204245
loss =  -7.3516974
loss =  -9.002981
loss =  -7.231237
loss =  -7.718582
loss =  -7.712365
loss =  -8.243162
loss =  -6.4188194
loss =  -6.4343343
loss =  -5.523883
loss =  -5.873423
loss =  -5.09745
loss =  -7.396429
loss =  -7.2200184
loss =  -7.6905746
loss =  -8.213547
loss =  -7.858914
loss =  -8.022937
loss =  -8.103178
loss =  -8.323828
loss =  -6.927555
loss =  -8.437996
loss =  -8.88225
loss =  -9.344342
loss =  -10.730779
loss =  -7.9609146
loss =  -9.40102
loss =  -9.952356
loss =  -7.921158
loss =  -8.126451
loss =  -7.9925613
loss =  -7.8936
loss =  -8.404976
loss =  -6.9845867
loss =  -7.72441
loss =  -8.377561
loss =  -8.574545
loss =  -7.8924723
loss =  -6.8763237
loss =  -6.818472
loss =  -7.8894186
loss =  -7.7881503
loss =  -8.065539
loss =  -9.336802
loss =  -8.783834
loss =  -6.7709327
loss =  -8.661354
loss =  -8.589481
loss =  -8.110414
loss =  -8.845647
loss =  -9.00506
loss =  -9.37616
loss =  -7.8190823
loss =  -8.552717
loss =  -7.790621
loss =  -7.4998236
loss =  -8.846541
loss =  -9.00185
loss =  -8.426907
loss =  -8.036767
loss =  -9.004072
loss =  -8.876736
loss =  -8.463791
loss =  -9.422459
loss =  -7.3568206
loss =  -8.307533
loss =  -9.101466
loss =  -8.0633745
loss =  -9.503323
loss =  -8.643425
loss =  -8.671588
loss =  -8.397198
loss =  -8.212399
loss =  -9.818773
loss =  -8.859404
loss =  -8.679943
loss =  -8.690428
loss =  -6.7672243
loss =  -9.323313
loss =  -9.181796
loss =  -8.296873
loss =  -8.218021
loss =  -8.698612
loss =  -8.307972
loss =  -7.2325373
loss =  -9.862539
loss =  -8.551041
loss =  -9.766462
loss =  -9.2387905
loss =  -7.9856634
loss =  -7.4531956
loss =  -9.242514
loss =  -8.216717
loss =  -7.4368315
loss =  -9.060469
loss =  -8.636359
loss =  -9.454287
loss =  -8.945732
loss =  -8.10067
loss =  -8.628794
loss =  -9.781238
loss =  -7.4817085
loss =  -7.9499235
loss =  -9.231924
loss =  -9.121517
loss =  -8.516777
loss =  -8.53772
loss =  -9.047075
loss =  -6.977271
loss =  -8.5093
loss =  -7.4618163
loss =  -9.548713
loss =  -9.109262
loss =  -8.161024
loss =  -9.756413
loss =  -9.487747
loss =  -7.661049
loss =  -8.542978
loss =  -8.568375
loss =  -8.526482
loss =  -9.336918
loss =  -9.292869
loss =  -8.780635
loss =  -8.634232
loss =  -8.855838
loss =  -8.168348
loss =  -8.998039
loss =  -6.749467
loss =  -9.892145
loss =  -6.712411
loss =  -8.057854
loss =  -7.623415
loss =  -8.640924
loss =  -8.021936
loss =  -8.722174
loss =  -8.688343
loss =  -7.0011473
loss =  -8.584612
loss =  -10.188713
loss =  -9.515013
loss =  -8.585558
loss =  -8.411743
loss =  -9.370348
loss =  -7.811352
loss =  -7.4951096
loss =  -9.321477
loss =  -8.848709
loss =  -9.638167
loss =  -9.7037115
loss =  -8.01646
loss =  -8.288901
loss =  -7.9208655
loss =  -9.394895
loss =  -9.629086
loss =  -7.0750456
loss =  -7.3466606
loss =  -8.525524
loss =  -8.162983
loss =  -8.140677
loss =  -8.524476
loss =  -8.278585
loss =  -8.303855
loss =  -7.5621357
loss =  -9.027628
loss =  -8.863192
loss =  -8.712463
loss =  -8.432366
loss =  -7.5925813
loss =  -7.6729116
loss =  -8.550707
loss =  -9.962597
loss =  -8.228359
loss =  -8.57876
loss =  -9.558187
loss =  -10.2037735
loss =  -8.858041
loss =  -9.256443
loss =  -8.934075
loss =  -9.422907
loss =  -8.251572
loss =  -8.240717
loss =  -8.391647
loss =  -9.099144
loss =  -8.7369995
loss =  -9.099574
loss =  -8.081765
loss =  -9.040325
loss =  -8.00634
loss =  -8.364947
loss =  -8.962902
loss =  -8.675971
loss =  -8.027038
loss =  -8.82942
loss =  -8.936093
loss =  -9.318258
loss =  -8.349281
loss =  -7.574607
loss =  -8.435751
loss =  -8.189688
loss =  -8.291354
loss =  -8.113847
loss =  -7.456213
loss =  -9.053526
loss =  -8.63292
loss =  -7.649855
loss =  -9.621365
loss =  -8.683357
loss =  -7.630263
loss =  -9.284666
loss =  -8.362158
loss =  -7.585112
loss =  -7.792265
loss =  -8.008369
loss =  -9.312316
loss =  -7.6710906
loss =  -8.059069
loss =  -7.7535005
loss =  -8.241203
loss =  -7.9035788
loss =  -9.072826
loss =  -9.419773
loss =  -7.940505
loss =  -8.815096
loss =  -8.407069
loss =  -8.787174
loss =  -8.486433
loss =  -7.8109117
loss =  -9.487677
loss =  -8.5368185
loss =  -9.706957
loss =  -9.676469
loss =  -8.606966
loss =  -8.600958
loss =  -9.964569
loss =  -8.268298
loss =  -9.048574
loss =  -8.375223
loss =  -7.13615
loss =  -7.335001
loss =  -9.322897
loss =  -6.8501806
loss =  -8.177149
loss =  -9.122232
loss =  -8.413665
loss =  -8.490215
loss =  -8.360773
loss =  -8.449283
loss =  -7.407682
loss =  -7.033538
loss =  -7.366744
loss =  -8.262691
loss =  -9.175417
loss =  -8.929638
loss =  -9.361689
loss =  -8.7695675
loss =  -9.254681
loss =  -9.898373
loss =  -7.7352552
loss =  -8.880513
loss =  -7.882633
loss =  -8.649614
loss =  -9.030376
loss =  -7.8974752
loss =  -7.785687
loss =  -9.002357
loss =  -8.806511
loss =  -8.37547
loss =  -8.841135
loss =  -8.585197
loss =  -7.89054
loss =  -8.270386
loss =  -8.530951
loss =  -8.496332
loss =  -7.436624
loss =  -8.432108
loss =  -8.095737
loss =  -7.0255027
loss =  -9.120754
loss =  -8.597446
loss =  -9.040432
loss =  -7.9914207
loss =  -8.995187
loss =  -8.992146
loss =  -8.679756
loss =  -8.230631
loss =  -8.39665
loss =  -9.373042
loss =  -9.265322
loss =  -8.807419
loss =  -7.936152
loss =  -8.854572
loss =  -8.746343
loss =  -8.392855
loss =  -8.311206
loss =  -8.176705
loss =  -7.6013265
loss =  -6.61623
loss =  -8.703634
loss =  -8.442789
loss =  -9.618432
loss =  -8.3556385
loss =  -7.80331
loss =  -9.144268
loss =  -7.3764057
loss =  -9.392246
loss =  -8.497136
loss =  -7.472568
loss =  -8.471014
loss =  -9.722087
loss =  -9.21723