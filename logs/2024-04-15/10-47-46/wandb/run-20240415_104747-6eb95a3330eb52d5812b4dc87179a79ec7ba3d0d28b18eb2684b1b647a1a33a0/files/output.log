{'wandb': {'project': 'sis', 'resume': 'allow', 'mode': 'run', 'name': '2024-04-15/10-47-46,', 'tags': [], 'id': '6eb95a3330eb52d5812b4dc87179a79ec7ba3d0d28b18eb2684b1b647a1a33a0'}, 'keops_build_path': '/Users/ajgeorge/.cache/keops/unknown/2024-04-15/10-47-46', 'merge_wandb_resume_cfg': True, 'restore_ckpt_from_wandb': True, 'target': {'_target_': 'stint_sampler.targets.targets.gmm', 'mean': 5.0, 'var': 1.0}, 'interpolant': {'_target_': 'stint_sampler.stint.linearInterpolants.linear', 'type': 'sin'}, 'model': {'_target_': 'stint_sampler.models.scoreNets.DenseNet', 'dim': 2, 'features': [20, 50, 200, 200, 50]}, 'seed': 1, 'T': 1.0, 'dim': 2, 'eps0': 1e-05, 'eps1': 1e-05, 'batch_size': 128, 'train': {'NtTrain': 10, 'epochs': 1000, 'epoch_steps': 4, 'learning_rate': 0.01}, 'solver': {'_target_': 'stint_sampler.stint.sis.half_sis'}, 'sampler': {'Nsamples': 10000, 'NtSampler': 1000}, 'out_dir': '/Users/ajgeorge/python/sis/logs/2024-04-15/10-47-46'}
[2024-04-15 10:47:52,905][root][INFO] - ---------------------------------------------------------------
[2024-04-15 10:47:52,907][root][INFO] - Run config:
wandb:
  project: sis
  resume: allow
  mode: run
  name: 2024-04-15/10-47-46,
  tags: []
  id: 6eb95a3330eb52d5812b4dc87179a79ec7ba3d0d28b18eb2684b1b647a1a33a0
keops_build_path: /Users/ajgeorge/.cache/keops/unknown/2024-04-15/10-47-46
merge_wandb_resume_cfg: true
restore_ckpt_from_wandb: true
target:
  _target_: stint_sampler.targets.targets.gmm
  mean: 5.0
  var: 1.0
interpolant:
  _target_: stint_sampler.stint.linearInterpolants.linear
  type: sin
model:
  _target_: stint_sampler.models.scoreNets.DenseNet
  dim: 2
  features:
  - 20
  - 50
  - 200
  - 200
  - 50
seed: 1
T: 1.0
dim: 2
eps0: 1.0e-05
eps1: 1.0e-05
batch_size: 128
train:
  NtTrain: 10
  epochs: 1000
  epoch_steps: 4
  learning_rate: 0.01
solver:
  _target_: stint_sampler.stint.sis.half_sis
sampler:
  Nsamples: 10000
  NtSampler: 1000
out_dir: /Users/ajgeorge/python/sis/logs/2024-04-15/10-47-46
[2024-04-15 10:47:52,907][root][INFO] - ---------------------------------------------------------------
[2024-04-15 10:47:53,550][jax._src.xla_bridge][INFO] - Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
[2024-04-15 10:47:53,550][jax._src.xla_bridge][INFO] - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
[2024-04-15 10:47:53,551][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: dlopen(libtpu.so, 0x0001): tried: 'libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OSlibtpu.so' (no such file), '/Users/ajgeorge/anaconda3/envs/sis/lib/python3.11/site-packages/jaxlib/../../../libtpu.so' (no such file), '/Users/ajgeorge/anaconda3/envs/sis/bin/../lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache), 'libtpu.so' (no such file), '/usr/local/lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache)
[2024-04-15 10:47:53,568][root][INFO] - Checkpoint directory: /Users/ajgeorge/python/sis/logs/2024-04-15/10-47-46/ckpt
loss =  -2.466167
loss =  -8.347751
loss =  -8.996714
loss =  -9.769745
loss =  -10.648758
loss =  -9.262558
loss =  -10.743235
loss =  -8.599524
loss =  -8.732399
loss =  -8.282934
loss =  -10.8146515
loss =  -9.849573
loss =  -9.468594
loss =  -9.471772
loss =  -12.116945
loss =  -10.460784
loss =  -11.117831
loss =  -10.791229
loss =  -9.811958
loss =  -10.917051
loss =  -10.363338
loss =  -10.690883
loss =  -11.0648155
loss =  -9.477942
loss =  -10.452668
loss =  -10.711131
loss =  -8.562467
loss =  -9.235586
loss =  -10.675329
loss =  -8.974325
loss =  -10.804554
loss =  -9.883587
loss =  -10.288277
loss =  -9.879335
loss =  -10.086309
loss =  -9.611351
loss =  -10.957525
loss =  -5.391532
loss =  -6.9318876
loss =  -6.019739
loss =  -6.9636664
loss =  -7.4191895
loss =  -7.655875
loss =  -8.714825
loss =  -9.20771
loss =  -9.756712
loss =  -10.198568
loss =  -10.091232
loss =  -8.938677
loss =  -10.5882015
loss =  -9.866835
loss =  -10.291068
loss =  -11.021876
loss =  -4.5464573
loss =  -8.480672
loss =  -10.193562
loss =  -9.879479
loss =  -8.707126
loss =  -10.7008295
loss =  -9.770539
loss =  -10.203448
loss =  -11.9387455
loss =  -9.200224
loss =  -9.949591
loss =  -10.853909
loss =  -9.303232
loss =  -10.587978
loss =  -11.065732
loss =  -10.230524
loss =  -8.349355
loss =  -7.479103
loss =  -7.564583
loss =  -7.9814796
loss =  -8.637174
loss =  -9.603184
loss =  -9.290916
loss =  -8.798426
loss =  -7.658427
loss =  -7.267601
loss =  -6.268749
loss =  -7.2985344
loss =  -7.0249043
loss =  -8.238129
loss =  -7.55614
loss =  -7.4643645
loss =  -8.853044
loss =  -8.496546
loss =  -8.742682
loss =  -8.410508
loss =  -8.023203
loss =  -9.600458
loss =  -8.7757435
loss =  -8.970221
loss =  -9.612915
loss =  -10.250586
loss =  -8.216613
loss =  -7.7602053
loss =  -8.74421
loss =  -5.330914
loss =  -6.107611
loss =  -5.0150642
loss =  -4.485347
loss =  -6.3144493
loss =  -6.933052
loss =  -5.2261777
loss =  -6.49502
loss =  -7.075371
loss =  -4.666292
loss =  -6.2071133
loss =  -5.388166
loss =  -5.848351
loss =  -5.814436
loss =  -6.652815
loss =  -5.4404206
loss =  -7.483967
loss =  -5.062727
loss =  -6.08334
loss =  -6.7374244
loss =  -5.745494
loss =  -5.917966
loss =  -7.1413927
loss =  -5.526988
loss =  -5.527241
loss =  -5.9423084
loss =  -6.589331
loss =  -6.028159
loss =  -4.8990974
loss =  -6.995469
loss =  -6.582943
loss =  -6.247754
loss =  -5.756426
loss =  -6.567252
loss =  -6.5759554
loss =  -6.314373
loss =  -5.514553
loss =  -6.2728662
loss =  -5.5037794
loss =  -6.168053
loss =  -7.1663713
loss =  -5.4709654
loss =  -5.1083903
loss =  -7.548299
loss =  -6.612666
loss =  -6.190365
loss =  -6.071944
loss =  -6.4814835
loss =  -6.511064
loss =  -6.506115
loss =  -7.0140867
loss =  -7.762149
loss =  -6.601762
loss =  -6.3516808
loss =  -7.5385427
loss =  -5.1522064
loss =  -5.1947126
loss =  -5.7780814
loss =  -5.2479906
loss =  -5.1873503
loss =  -6.865741
loss =  -7.3284636
loss =  -6.9563713
loss =  -7.3789735
loss =  -5.3063564
loss =  -6.701842
loss =  -6.538827
loss =  -7.0634613
loss =  -7.4507
loss =  -6.7575865
loss =  -6.5127525
loss =  -6.7456365
loss =  -7.6215305
loss =  -6.911871
loss =  -6.140745
loss =  -6.5175095
loss =  -6.739571
loss =  -7.939522
loss =  -7.4644594
loss =  -6.0217896
loss =  -6.0023537
loss =  -6.102555
loss =  -6.6269116
loss =  -7.3083925
loss =  -7.026179
loss =  -7.1189003
loss =  -6.677312
loss =  -6.608984
loss =  -7.652496
loss =  -5.8345413
loss =  -5.8526335
loss =  -7.3697023
loss =  -6.5067754
loss =  -6.2582293
loss =  -6.07876
loss =  -7.6028914
loss =  -6.67138
loss =  -6.225358
loss =  -7.75385
loss =  -6.9641466
loss =  -7.194339
loss =  -6.1729746
loss =  -6.915659
loss =  -6.3837395
loss =  -7.0632486
loss =  -5.896245
loss =  -8.329835
loss =  -6.169932
loss =  -8.465135
loss =  -6.336608
loss =  -6.8795567
loss =  -7.497854
loss =  -7.7465773
loss =  -7.2141585
loss =  -6.511707
loss =  -6.805482
loss =  -7.229884
loss =  -6.7319493
loss =  -7.062782
loss =  -7.352109
loss =  -7.213235
loss =  -7.1295347
loss =  -7.0175033
loss =  -7.671985
loss =  -6.6822615
loss =  -6.9638376
loss =  -6.2068973
loss =  -7.637474
loss =  -7.047337
loss =  -7.5975466
loss =  -6.6355658
loss =  -5.9430065
loss =  -7.2364497
loss =  -7.2965937
loss =  -6.859762
loss =  -7.918823
loss =  -6.603251
loss =  -6.7445507
loss =  -6.9478855
loss =  -6.4085326
loss =  -7.37768
loss =  -7.3332214
loss =  -7.1441784
loss =  -5.8484616
loss =  -6.4999623
loss =  -6.347077
loss =  -7.280966
loss =  -6.558959
loss =  -7.117654
loss =  -7.557564
loss =  -6.8492723
loss =  -5.176519
loss =  -7.6215897
loss =  -7.1468096
loss =  -6.7309685
loss =  -7.8050146
loss =  -7.6872683
loss =  -6.680991
loss =  -7.013905
loss =  -7.2484245
loss =  -6.91989
loss =  -6.472427
loss =  -6.625436
loss =  -5.88165
loss =  -6.191121
loss =  -6.8639207
loss =  -6.5008907
loss =  -6.835349
loss =  -6.246503
loss =  -6.8640256
loss =  -9.057354
loss =  -6.5684423
loss =  -6.963249
loss =  -7.100213
loss =  -7.2710495
loss =  -7.708146
loss =  -6.112868
loss =  -6.269799
loss =  -7.629525
loss =  -7.430028
loss =  -6.124954
loss =  -8.94907
loss =  -6.860975
loss =  -7.557177
loss =  -7.3397655
loss =  -6.8696547
loss =  -7.2211485
loss =  -6.452171
loss =  -6.205799
loss =  -6.7909174
loss =  -7.292476
loss =  -5.5897846
loss =  -6.835742
loss =  -6.59223
loss =  -6.2063136
loss =  -8.3101635
loss =  -7.784886
loss =  -8.146339
loss =  -6.2762585
loss =  -7.130501
loss =  -7.349431
loss =  -7.1869845
loss =  -6.7018104
loss =  -7.1481256
loss =  -7.4319096
loss =  -6.6477547
loss =  -6.4749613
loss =  -6.9267383
loss =  -7.323763
loss =  -7.36586
loss =  -6.577159
loss =  -8.574469
loss =  -6.8693595
loss =  -6.995983
loss =  -8.014734
loss =  -6.688987
loss =  -8.004174
loss =  -5.6523514
loss =  -6.681618
loss =  -6.3901315
loss =  -7.2816076
loss =  -7.0282803
loss =  -6.5335236
loss =  -7.3316574
loss =  -6.727542
loss =  -6.6079645
loss =  -7.0766606
loss =  -6.1108284
loss =  -7.56291
loss =  -6.6194124
loss =  -6.305819
loss =  -7.054446
loss =  -6.9452243
loss =  -6.9469514
loss =  -7.6065893
loss =  -7.7460556
loss =  -7.0658684
loss =  -8.1225815
loss =  -6.775997
loss =  -6.882637
loss =  -6.547129
loss =  -7.5722957
loss =  -6.0211096
loss =  -6.4021664
loss =  -8.690326
loss =  -7.31197
loss =  -5.3884706
loss =  -6.198182
loss =  -6.6298537
loss =  -7.2660074
loss =  -7.0564694
loss =  -7.722062
loss =  -7.223071
loss =  -7.412304
loss =  -6.8350015
loss =  -8.491857
loss =  -7.0950575
loss =  -7.595399
loss =  -6.8386545
loss =  -6.4365997
loss =  -7.506154
loss =  -6.8107266
loss =  -6.108344
loss =  -6.9578714
loss =  -6.8615527
loss =  -6.0469065
loss =  -5.5085077
loss =  -7.033742
loss =  -6.347433
loss =  -7.1532564
loss =  -6.9606447
loss =  -6.209895
loss =  -7.7518463
loss =  -6.557405
loss =  -6.6911583
loss =  -7.438263
loss =  -7.6838984
loss =  -7.2034564
loss =  -7.721689
loss =  -6.302333
loss =  -7.6140575
loss =  -7.177902
loss =  -6.34933
loss =  -4.5241137
loss =  -5.857626
loss =  -7.218313
loss =  -6.4439783
loss =  -5.460767
loss =  -8.009209
loss =  -8.082449
loss =  -9.091302
loss =  -7.376186
loss =  -7.2698407
loss =  -8.081024
loss =  -7.0797853
loss =  -6.10945
loss =  -7.3071356
loss =  -6.9932246
loss =  -6.732661
loss =  -7.6360745
loss =  -6.5460014
loss =  -7.5814867
[2024-04-15 10:48:48,127][root][CRITICAL] - 'method' object is not subscriptable
Traceback (most recent call last):
  File "/Users/ajgeorge/python/sis/main.py", line 77, in main
    plotObj.make_hist_plot(ax)
  File "/Users/ajgeorge/python/sis/stint_sampler/eval/plotter.py", line 12, in make_hist_plot
    vals, xedges, yedges = np.histogram2d(self.data[:, 0],self.data[:, 1], 40)
                                          ~~~~~~~~~^^^^^^
TypeError: 'method' object is not subscriptable